name: Deploy Cold Email Generator

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      setup_infrastructure:
        description: 'Set up AWS infrastructure'
        required: false
        default: false
        type: boolean

env:
  DOCKER_REGISTRY: ghcr.io
  DOCKER_IMAGE: ghcr.io/${{ github.repository_owner }}/cold-email:${{ github.sha }}
  DOCKER_IMAGE_LATEST: ghcr.io/${{ github.repository_owner }}/cold-email:latest
  AWS_USER: ubuntu
  APP_NAME: cold-email
  AWS_REGION: ${{ secrets.AWS_REGION }}

jobs:
  validate:
    name: Validate Application
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Validate project structure
        run: |
          echo "Validating project structure..."
          python -c "import app.main" || echo "Validation failed but continuing"

  build:
    name: Build and Push Docker Image
    needs: validate
    runs-on: ubuntu-latest
    # Add permissions for packages
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: |
            ${{ env.DOCKER_IMAGE }}
            ${{ env.DOCKER_IMAGE_LATEST }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  infra-setup:
    name: AWS Infrastructure Setup
    needs: build
    runs-on: ubuntu-latest
    environment: production
    # Make this step manual to avoid unexpected infrastructure changes
    if: github.event.inputs.setup_infrastructure == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Set up SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.AWS_SSH_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H github.com >> ~/.ssh/known_hosts
          echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
      
      - name: Set up AWS infrastructure
        run: |
          chmod +x deploy/aws-k8s/aws-infrastructure.sh
          cd deploy/aws-k8s
          ./aws-infrastructure.sh
      
      - name: Wait for instances to be ready
        run: |
          echo "Waiting for instances to be ready..."
          sleep 120  # Give more time for instances to be registered
          
      - name: Find healthy EC2 instance
        run: |
          chmod +x deploy/aws-k8s/get-healthy-instance.sh
          # Check if ASG exists and has instances
          ASG_EXISTS=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names ${APP_NAME}-asg --query "length(AutoScalingGroups)" --output text || echo "0")
          
          if [ "$ASG_EXISTS" == "0" ]; then
            echo "Auto Scaling Group ${APP_NAME}-asg does not exist or has no instances"
            exit 1
          fi
          
          INSTANCE_COUNT=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names ${APP_NAME}-asg --query "AutoScalingGroups[0].Instances | length(@)" --output text)
          
          if [ "$INSTANCE_COUNT" == "0" ]; then
            echo "No instances found in Auto Scaling Group ${APP_NAME}-asg"
            exit 1
          fi
          
          # Try multiple times to find a healthy instance
          MAX_RETRIES=5
          for i in $(seq 1 $MAX_RETRIES); do
            echo "Attempt $i to find a healthy instance..."
            EC2_IP=$(./deploy/aws-k8s/get-healthy-instance.sh || echo "")
            
            if [ ! -z "$EC2_IP" ]; then
              echo "EC2_IP=$EC2_IP" >> $GITHUB_ENV
              echo "Found healthy instance with IP $EC2_IP"
              break
            fi
            
            if [ $i -eq $MAX_RETRIES ]; then
              echo "Failed to find a healthy instance after $MAX_RETRIES attempts"
              exit 1
            fi
            
            echo "Waiting 30 seconds before next attempt..."
            sleep 30
          done
      
      - name: Set up Kubernetes
        run: |
          scp deploy/aws-k8s/k8s-setup.sh ${AWS_USER}@${EC2_IP}:~/
          scp deploy/aws-k8s/k8s-deploy.sh ${AWS_USER}@${EC2_IP}:~/
          ssh ${AWS_USER}@${EC2_IP} "chmod +x ~/k8s-setup.sh ~/k8s-deploy.sh"
          ssh ${AWS_USER}@${EC2_IP} "export GROQ_API_KEY='${{ secrets.GROQ_API_KEY }}' && ~/k8s-setup.sh"
          echo "Kubernetes setup completed"
      
      # Add a verification step
      - name: Verify infrastructure
        run: |
          echo "Verifying AWS infrastructure..."
          # Verify Auto Scaling Group
          aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names ${APP_NAME}-asg
          # Verify Load Balancer
          aws elbv2 describe-load-balancers --names ${APP_NAME}-lb
          
          # Store LB_DNS as an output
          LB_DNS=$(aws elbv2 describe-load-balancers \
            --names ${APP_NAME}-lb \
            --query 'LoadBalancers[0].DNSName' \
            --output text)
          echo "LB_DNS=$LB_DNS" >> $GITHUB_ENV
          echo "Load balancer DNS: $LB_DNS"

  check-infra:
    name: Check Infrastructure
    needs: build
    runs-on: ubuntu-latest
    environment: production
    if: github.event.inputs.setup_infrastructure != 'true'
    outputs:
      infra_exists: ${{ steps.check-asg.outputs.infra_exists }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Check if infrastructure exists
        id: check-asg
        run: |
          ASG_EXISTS=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names ${APP_NAME}-asg --query "length(AutoScalingGroups)" --output text || echo "0")
          if [ "$ASG_EXISTS" == "0" ]; then
            echo "::warning::Infrastructure does not exist yet. Please run the workflow with 'setup_infrastructure' option enabled first."
            echo "infra_exists=false" >> $GITHUB_OUTPUT
          else
            echo "Infrastructure exists."
            echo "infra_exists=true" >> $GITHUB_OUTPUT
          fi

  deploy:
    name: Deploy Application
    needs: [build, check-infra]
    if: >-
      always() && 
      (needs.check-infra.result == 'success' && needs.check-infra.outputs.infra_exists == 'true')
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Set up SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.AWS_SSH_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H github.com >> ~/.ssh/known_hosts
          echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
      
      - name: Verify auto-scaling group exists
        run: |
          # Check if ASG exists
          ASG_EXISTS=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names ${APP_NAME}-asg --query "length(AutoScalingGroups)" --output text || echo "0")
          
          if [ "$ASG_EXISTS" == "0" ]; then
            echo "ERROR: Auto Scaling Group ${APP_NAME}-asg does not exist. You need to run the workflow with 'setup_infrastructure' option enabled first."
            exit 1
          fi
      
      - name: Find healthy EC2 instance
        run: |
          chmod +x deploy/aws-k8s/get-healthy-instance.sh
          
          # Try multiple times to find a healthy instance
          MAX_RETRIES=5
          for i in $(seq 1 $MAX_RETRIES); do
            echo "Attempt $i to find a healthy instance..."
            EC2_IP=$(./deploy/aws-k8s/get-healthy-instance.sh || echo "")
            
            if [ ! -z "$EC2_IP" ]; then
              echo "EC2_IP=$EC2_IP" >> $GITHUB_ENV
              echo "Found healthy instance with IP $EC2_IP"
              break
            fi
            
            if [ $i -eq $MAX_RETRIES ]; then
              echo "Failed to find a healthy instance after $MAX_RETRIES attempts"
              echo "Please ensure that the infrastructure setup has been completed."
              exit 1
            fi
            
            echo "Waiting 30 seconds before next attempt..."
            sleep 30
          done
      
      - name: Get load balancer DNS
        run: |
          LB_DNS=$(aws elbv2 describe-load-balancers \
            --names ${APP_NAME}-lb \
            --query 'LoadBalancers[0].DNSName' \
            --output text || echo "")
            
          if [ -z "$LB_DNS" ]; then
            echo "ERROR: Load balancer ${APP_NAME}-lb not found. Infrastructure setup may be incomplete."
            exit 1
          fi
          
          echo "LB_DNS=$LB_DNS" >> $GITHUB_ENV
          echo "Load balancer DNS: $LB_DNS"
      
      - name: Deploy application
        run: |
          echo "Deploying application to Kubernetes..."
          ssh ${AWS_USER}@${EC2_IP} "export DOCKER_IMAGE=${DOCKER_IMAGE} && export LB_DNS=${LB_DNS} && ~/k8s-deploy.sh"
          echo "Application deployed successfully"

  infra-deploy:
    name: Deploy to Infrastructure
    needs: [infra-setup]
    if: success()
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Set up SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.AWS_SSH_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H github.com >> ~/.ssh/known_hosts
          echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
      
      - name: Find healthy EC2 instance
        run: |
          chmod +x deploy/aws-k8s/get-healthy-instance.sh
          EC2_IP=$(./deploy/aws-k8s/get-healthy-instance.sh)
          echo "EC2_IP=$EC2_IP" >> $GITHUB_ENV
          echo "Using EC2 instance with IP $EC2_IP for deployment"
      
      - name: Get load balancer DNS
        run: |
          LB_DNS=$(aws elbv2 describe-load-balancers \
            --names ${APP_NAME}-lb \
            --query 'LoadBalancers[0].DNSName' \
            --output text)
          echo "LB_DNS=$LB_DNS" >> $GITHUB_ENV
          echo "Load balancer DNS: $LB_DNS"
      
      - name: Deploy application
        run: |
          echo "Deploying application to Kubernetes after infrastructure setup..."
          ssh ${AWS_USER}@${EC2_IP} "export DOCKER_IMAGE=${DOCKER_IMAGE} && export LB_DNS=${LB_DNS} && ~/k8s-deploy.sh"
          echo "Application deployed successfully"

  monitor:
    name: Monitor Deployment
    needs: [deploy, infra-deploy]
    if: always() && (success('deploy') || success('infra-deploy'))
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Set up SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.AWS_SSH_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H github.com >> ~/.ssh/known_hosts
          echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
      
      - name: Find healthy EC2 instance
        run: |
          chmod +x deploy/aws-k8s/get-healthy-instance.sh
          EC2_IP=$(./deploy/aws-k8s/get-healthy-instance.sh)
          echo "EC2_IP=$EC2_IP" >> $GITHUB_ENV
          echo "Using EC2 instance with IP $EC2_IP for deployment"
      
      - name: Check Kubernetes deployment status
        run: |
          ssh ${AWS_USER}@${EC2_IP} "kubectl get pods -n cold-email"
          ssh ${AWS_USER}@${EC2_IP} "kubectl get svc -n cold-email"
      
      - name: Get load balancer DNS
        run: |
          LB_DNS=$(aws elbv2 describe-load-balancers \
            --names ${APP_NAME}-lb \
            --query 'LoadBalancers[0].DNSName' \
            --output text)
          echo "LB_DNS=$LB_DNS" >> $GITHUB_ENV
          echo "Load balancer DNS: $LB_DNS"
      
      - name: Check application health
        run: |
          echo "Checking application health at http://${LB_DNS}/_stcore/health"
          sleep 60  # Wait for application to be fully available
          curl -s -f -m 10 "http://${LB_DNS}/_stcore/health" || echo "Health check failed, application may need more time to become available"
          echo "Application is accessible at: http://${LB_DNS}" 