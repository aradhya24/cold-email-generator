name: Deploy Cold Email Generator

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      setup_infrastructure:
        description: 'Set up AWS infrastructure'
        required: false
        default: true
        type: boolean

env:
  DOCKER_REGISTRY: ghcr.io
  DOCKER_IMAGE: ghcr.io/${{ github.repository_owner }}/cold-email:${{ github.sha }}
  DOCKER_IMAGE_LATEST: ghcr.io/${{ github.repository_owner }}/cold-email:latest
  AWS_USER: ubuntu
  APP_NAME: cold-email
  AWS_REGION: ${{ secrets.AWS_REGION }}

jobs:
  build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      
      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: |
            ${{ env.DOCKER_IMAGE }}
            ${{ env.DOCKER_IMAGE_LATEST }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    name: Deploy Application
    needs: build
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Set up SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.AWS_SSH_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H github.com >> ~/.ssh/known_hosts
          echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
      
      - name: Set up infrastructure if needed or requested
        run: |
          # Check if infrastructure setup is requested
          if [[ "${{ github.event.inputs.setup_infrastructure }}" == "true" || "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "Setting up infrastructure..."
            chmod +x deploy/aws-k8s/aws-infrastructure.sh
            cd deploy/aws-k8s
            ./aws-infrastructure.sh
            cd ../..
            echo "Waiting for instances to be ready..."
            sleep 120
          else
            # Check if ASG exists
            ASG_EXISTS=$(aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names ${APP_NAME}-asg --query "length(AutoScalingGroups)" --output text || echo "0")
            if [ "$ASG_EXISTS" == "0" ]; then
              echo "Infrastructure does not exist yet. Setting it up..."
              chmod +x deploy/aws-k8s/aws-infrastructure.sh
              cd deploy/aws-k8s
              ./aws-infrastructure.sh
              cd ../..
              echo "Waiting for instances to be ready..."
              sleep 120
            else
              echo "Infrastructure already exists, skipping setup."
            fi
          fi
      
      - name: Find healthy EC2 instance
        run: |
          chmod +x deploy/aws-k8s/get-healthy-instance.sh
          
          # Try multiple times to find a healthy instance
          MAX_RETRIES=5
          
          for i in $(seq 1 $MAX_RETRIES); do
            echo "Attempt $i to find a healthy instance..."
            EC2_IP=$(./deploy/aws-k8s/get-healthy-instance.sh || echo "")
            
            if [ ! -z "$EC2_IP" ]; then
              echo "EC2_IP=$EC2_IP" >> $GITHUB_ENV
              echo "Found healthy instance with IP $EC2_IP"
              break
            fi
            
            if [ $i -eq $MAX_RETRIES ]; then
              # Try a final alternative approach - get any running instance
              echo "Trying to find any running instance as fallback..."
              INSTANCE_ID=$(aws ec2 describe-instances \
                --filters "Name=tag:aws:autoscaling:groupName,Values=${APP_NAME}-asg" "Name=instance-state-name,Values=running" \
                --query "Reservations[0].Instances[0].InstanceId" \
                --output text)
              
              if [ "$INSTANCE_ID" != "None" ] && [ ! -z "$INSTANCE_ID" ]; then
                EC2_IP=$(aws ec2 describe-instances \
                  --instance-ids $INSTANCE_ID \
                  --query "Reservations[0].Instances[0].PublicIpAddress" \
                  --output text)
                
                if [ "$EC2_IP" != "None" ] && [ ! -z "$EC2_IP" ]; then
                  echo "FALLBACK: Using instance $INSTANCE_ID with IP $EC2_IP"
                  echo "EC2_IP=$EC2_IP" >> $GITHUB_ENV
                  break
                fi
              fi
              
              echo "Failed to find a healthy instance after all attempts"
              exit 1
            fi
            
            echo "Waiting 30 seconds before next attempt..."
            sleep 30
          done
      
      - name: Set up Kubernetes if needed
        run: |
          if ! ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 ${AWS_USER}@${EC2_IP} "kubectl get namespace ${APP_NAME} 2>/dev/null"; then
            echo "Setting up Kubernetes..."
            scp -o StrictHostKeyChecking=no deploy/aws-k8s/k8s-setup.sh ${AWS_USER}@${EC2_IP}:~/
            scp -o StrictHostKeyChecking=no deploy/aws-k8s/k8s-deploy.sh ${AWS_USER}@${EC2_IP}:~/
            ssh -o StrictHostKeyChecking=no ${AWS_USER}@${EC2_IP} "chmod +x ~/k8s-setup.sh ~/k8s-deploy.sh"
            ssh -o StrictHostKeyChecking=no ${AWS_USER}@${EC2_IP} "export GROQ_API_KEY='${{ secrets.GROQ_API_KEY }}' && ~/k8s-setup.sh"
            echo "Kubernetes setup completed"
          else
            echo "Kubernetes already set up"
          fi
      
      - name: Get load balancer DNS
        run: |
          LB_DNS=$(aws elbv2 describe-load-balancers \
            --names ${APP_NAME}-lb \
            --query 'LoadBalancers[0].DNSName' \
            --output text)
          echo "LB_DNS=$LB_DNS" >> $GITHUB_ENV
      
      - name: Deploy application
        run: |
          echo "Deploying application to Kubernetes..."
          scp -o StrictHostKeyChecking=no deploy/aws-k8s/k8s-deploy.sh ${AWS_USER}@${EC2_IP}:~/ || true
          ssh -o StrictHostKeyChecking=no ${AWS_USER}@${EC2_IP} "chmod +x ~/k8s-deploy.sh" || true
          ssh -o StrictHostKeyChecking=no ${AWS_USER}@${EC2_IP} "export DOCKER_IMAGE=${DOCKER_IMAGE} && export LB_DNS=${LB_DNS} && ~/k8s-deploy.sh"
          echo "Application deployed successfully"
      
      - name: Monitor deployment
        run: |
          echo "Checking Kubernetes deployment status..."
          ssh -o StrictHostKeyChecking=no ${AWS_USER}@${EC2_IP} "kubectl get pods -n ${APP_NAME}" || true
          ssh -o StrictHostKeyChecking=no ${AWS_USER}@${EC2_IP} "kubectl get svc -n ${APP_NAME}" || true
          
          echo "Waiting for application to be fully available..."
          sleep 60
          
          echo "Checking application health at http://${LB_DNS}/_stcore/health"
          curl -s -f -m 10 "http://${LB_DNS}/_stcore/health" || echo "Health check failed, application may need more time to become available"
          echo "Application is accessible at: http://${LB_DNS}" 