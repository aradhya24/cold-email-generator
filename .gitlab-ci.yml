image: docker:20.10.16

services:
  - docker:20.10.16-dind

variables:
  DOCKER_HOST: tcp://docker:2375
  DOCKER_TLS_CERTDIR: ""
  DOCKER_DRIVER: overlay2
  DOCKER_REGISTRY: ${CI_REGISTRY}
  DOCKER_IMAGE: ${CI_REGISTRY}/aradhya24/cold-email-generator:${CI_COMMIT_SHA}
  AWS_USER: ubuntu
  LB_DNS: ${LB_DNS}

stages:
  - validate
  - build
  - deploy
  - monitor

validate:
  image: python:3.9-slim
  stage: validate
  script:
    - apt-get update && apt-get install -y python3-pip
    - pip install -r requirements.txt
    - echo "Validating project structure..."
    - python -c "import app.main" || echo "Validation failed but continuing"

build:
  stage: build
  script: 
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY 
    - docker build --pull -t $DOCKER_IMAGE .
    - docker tag $DOCKER_IMAGE $CI_REGISTRY/aradhya24/cold-email-generator:latest
    - docker push $DOCKER_IMAGE 
    - docker push $CI_REGISTRY/aradhya24/cold-email-generator:latest

deploy_setup:
  stage: deploy
  image: python:3.9-slim
  only:
    - main
  when: manual
  script:
    - apt-get update && apt-get install -y openssh-client gettext-base awscli
    - mkdir -p ~/.ssh && chmod 700 ~/.ssh
    - echo "$AWS_SSH_KEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval $(ssh-agent -s) && ssh-add ~/.ssh/id_rsa
    - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
    
    # Get healthy EC2 instance
    - chmod +x scripts/get_healthy_instance.sh
    - EC2_IP=$(./scripts/get_healthy_instance.sh)
    - echo "Using EC2 instance with IP $EC2_IP for deployment"
    
    # Setup Kubernetes
    - ssh ${AWS_USER}@${EC2_IP} "mkdir -p ~/k8s ~/scripts"
    - scp -r k8s/* ${AWS_USER}@${EC2_IP}:~/k8s/
    - scp scripts/setup-k8s.sh ${AWS_USER}@${EC2_IP}:~/scripts/
    - ssh ${AWS_USER}@${EC2_IP} "chmod +x ~/scripts/setup-k8s.sh"
    - ssh ${AWS_USER}@${EC2_IP} "export GROQ_API_KEY=${GROQ_API_KEY} && ~/scripts/setup-k8s.sh"

deploy:
  stage: deploy
  image: python:3.9-slim
  before_script: |
    apt-get update
    apt-get install -y curl unzip openssh-client gettext-base jq
    # Install AWS CLI v2
    curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
    unzip awscliv2.zip
    ./aws/install
    # Setup SSH
    mkdir -p ~/.ssh && chmod 700 ~/.ssh
    echo "$AWS_SSH_KEY" | tr -d '\r' > ~/.ssh/id_rsa
    chmod 600 ~/.ssh/id_rsa
    eval $(ssh-agent -s) && ssh-add ~/.ssh/id_rsa
    echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
    chmod 600 ~/.ssh/config
    # Print public key for debugging
    echo "### SSH public key being used (add this to authorized_keys on EC2): ###"
    ssh-keygen -y -f ~/.ssh/id_rsa
    echo "###################################################################"
  script: |
    # Configure AWS credentials
    export AWS_DEFAULT_REGION=us-east-1
    export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
    export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
    
    echo "Finding EC2 instance with tag Name=cold-email-instance"
    # Find all instances with the tag Name=cold-email-instance
    INSTANCES_JSON=$(aws ec2 describe-instances \
      --filters "Name=tag:Name,Values=cold-email-instance" "Name=instance-state-name,Values=running" \
      --query "Reservations[*].Instances[*].{InstanceId:InstanceId,PublicIpAddress:PublicIpAddress,LaunchTime:LaunchTime}" \
      --output json)
    
    # Count instances
    INSTANCE_COUNT=$(echo $INSTANCES_JSON | jq '.[0] | length')
    echo "Found $INSTANCE_COUNT running instances"
    
    if [ "$INSTANCE_COUNT" -eq "0" ]; then
      echo "No instances found. Launching a new one..."
      # Make the launch script executable
      chmod +x scripts/launch_ec2.sh
      # Run the launch script
      ./scripts/launch_ec2.sh
      # Get the IP of the new instance
      sleep 30  # Give some time for the instance to initialize
      EC2_IP=$(aws ec2 describe-instances \
        --filters "Name=tag:Name,Values=cold-email-instance" "Name=instance-state-name,Values=running" \
        --query "Reservations[0].Instances[0].PublicIpAddress" \
        --output text)
    else
      # If we have multiple instances, use the newest one
      echo "Selecting the most recently launched instance"
      EC2_IP=$(echo $INSTANCES_JSON | jq -r '.[0] | sort_by(.LaunchTime) | reverse | .[0].PublicIpAddress')
    fi
    
    echo "Deploying to instance: $EC2_IP"
    
    # Allow some time for SSH to be available (especially for new instances)
    echo "Waiting for SSH to become available..."
    for i in {1..10}; do
      echo "Attempt $i: Testing SSH connection..."
      if ssh -v -o ConnectTimeout=10 ${AWS_USER}@${EC2_IP} "echo SSH connection successful"; then
        echo "SSH connection established!"
        break
      else
        echo "SSH connection failed. Waiting 30 seconds before retry..."
        if [ $i -eq 3 ]; then
          echo "Three failed attempts. Printing instance details for debugging:"
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=public-ip-address,Values=$EC2_IP" \
            --query "Reservations[0].Instances[0].InstanceId" \
            --output text)
          aws ec2 describe-instances --instance-ids $INSTANCE_ID
          
          echo "This EC2 instance was likely launched with a different key pair."
          echo "Please either:"
          echo "1. Update AWS_SSH_KEY in GitLab CI/CD variables to match the key used to launch this instance"
          echo "2. Terminate this instance and let the pipeline create a new one with the correct key"
          echo "3. SSH into the instance using the correct key and add the above public key to ~/.ssh/authorized_keys"
        fi
        sleep 30
      fi
      
      if [ $i -eq 10 ]; then
        echo "Could not establish SSH connection after 10 attempts. Exiting."
        exit 1
      fi
    done
    
    # Create directories on the instance
    echo "Creating directories on the instance..."
    ssh ${AWS_USER}@${EC2_IP} "mkdir -p ~/k8s ~/scripts"
    
    # Copy all script files
    echo "Copying deployment scripts to the instance..."
    scp -v scripts/setup-k8s.sh ${AWS_USER}@${EC2_IP}:~/scripts/
    scp -v scripts/deploy-k8s.sh ${AWS_USER}@${EC2_IP}:~/scripts/
    scp -v scripts/deploy.sh ${AWS_USER}@${EC2_IP}:~/scripts/
    
    # Copy Kubernetes config files
    echo "Copying Kubernetes config files..."
    scp -v -r k8s/* ${AWS_USER}@${EC2_IP}:~/k8s/
    
    # Make scripts executable
    echo "Making scripts executable..."
    ssh ${AWS_USER}@${EC2_IP} "chmod +x ~/scripts/*.sh"
    
    # Execute setup script with a direct approach
    echo "Setting up the EC2 instance with required dependencies..."
    ssh ${AWS_USER}@${EC2_IP} "sudo apt-get update && sudo apt-get install -y docker.io nginx"
    ssh ${AWS_USER}@${EC2_IP} "sudo systemctl enable docker && sudo systemctl start docker"
    ssh ${AWS_USER}@${EC2_IP} "sudo systemctl enable nginx && sudo systemctl start nginx"
    
    echo "Creating simple Kubernetes namespace directory structure..."
    ssh ${AWS_USER}@${EC2_IP} "mkdir -p ~/k8s/namespaces/cold-email"
    
    # Process the deployment file with environment variables
    echo "Preparing deployment files..."
    envsubst < k8s/deployment.yaml > k8s/deployment.tmp.yaml
    
    # Copy deployment files
    echo "Copying deployment files..."
    scp -v k8s/deployment.tmp.yaml ${AWS_USER}@${EC2_IP}:~/k8s/deployment.yaml
    
    # Create a simple configuration to run the application without Kubernetes
    echo "Creating a simple docker-compose configuration..."
    cat > docker-compose.yml << 'EOF'
    version: '3'
    services:
      app:
        image: ${CI_REGISTRY}/aradhya24/cold-email-generator:${CI_COMMIT_SHA}
        ports:
          - "8501:8501"
        environment:
          - GROQ_API_KEY=${GROQ_API_KEY}
    EOF
    
    # Copy the docker-compose file
    scp -v docker-compose.yml ${AWS_USER}@${EC2_IP}:~/docker-compose.yml
    
    # Run the application with Docker directly
    echo "Running the application with Docker..."
    ssh ${AWS_USER}@${EC2_IP} "sudo docker login -u gitlab-ci-token -p ${CI_JOB_TOKEN} ${CI_REGISTRY}"
    ssh ${AWS_USER}@${EC2_IP} "export CI_REGISTRY=${CI_REGISTRY} && export CI_COMMIT_SHA=${CI_COMMIT_SHA} && export GROQ_API_KEY=${GROQ_API_KEY} && sudo -E docker-compose -f ~/docker-compose.yml up -d || sudo docker run -d --name cold-email -p 8501:8501 -e GROQ_API_KEY=${GROQ_API_KEY} ${CI_REGISTRY}/aradhya24/cold-email-generator:${CI_COMMIT_SHA}"
    
    # Set up a simple nginx reverse proxy
    echo "Setting up nginx reverse proxy..."
    cat > nginx.conf << 'EOF'
    server {
      listen 80;
      server_name _;
      
      location / {
        proxy_pass http://localhost:8501;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
      }
    }
    EOF
    
    scp -v nginx.conf ${AWS_USER}@${EC2_IP}:~/nginx.conf
    ssh ${AWS_USER}@${EC2_IP} "sudo mkdir -p /etc/nginx/conf.d/ && sudo cp ~/nginx.conf /etc/nginx/conf.d/default.conf && sudo systemctl reload nginx"
    
    # Get the public IP of the instance for access
    PUBLIC_IP=$(aws ec2 describe-instances \
      --filters "Name=instance-id,Values=$(aws ec2 describe-instances \
      --filters "Name=public-ip-address,Values=$EC2_IP" \
      --query "Reservations[0].Instances[0].InstanceId" \
      --output text)" \
      --query "Reservations[0].Instances[0].PublicIpAddress" \
      --output text)
    
    # If PUBLIC_IP is empty, use EC2_IP
    if [ -z "$PUBLIC_IP" ]; then
      PUBLIC_IP=$EC2_IP
    fi
    
    echo "==========================================================="
    echo "Application deployed successfully and is accessible at:"
    echo "http://${PUBLIC_IP}"
    echo "==========================================================="
    
    # Update the LB_DNS variable to use the public IP (fixing artifact format)
    echo "Updating LB_DNS variable to use the instance public IP..."
    echo "LB_DNS=${PUBLIC_IP}" > lb_dns.env
    
    echo "Deployment process completed successfully!"
  environment:
    name: production
    url: http://${LB_DNS}
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
      when: manual
    - when: never
  artifacts:
    reports:
      dotenv: lb_dns.env

monitor:
  stage: monitor
  image: python:3.9-slim
  only:
    - main
  script:
    - apt-get update && apt-get install -y openssh-client curl awscli
    - mkdir -p ~/.ssh && chmod 700 ~/.ssh
    - echo "$AWS_SSH_KEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval $(ssh-agent -s) && ssh-add ~/.ssh/id_rsa
    - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
    
    # Get healthy EC2 instance
    - chmod +x scripts/get_healthy_instance.sh
    - EC2_IP=$(./scripts/get_healthy_instance.sh)
    
    # Check Kubernetes deployment
    - ssh ${AWS_USER}@${EC2_IP} "kubectl get pods -n cold-email"
    - ssh ${AWS_USER}@${EC2_IP} "kubectl get svc -n cold-email"
    
    # Get load balancer DNS if not set
    - |
      if [ -z "$LB_DNS" ]; then
        export LB_DNS=$(aws elbv2 describe-load-balancers \
          --names cold-email-lb \
          --query 'LoadBalancers[0].DNSName' \
          --output text)
      fi
    
    # Check application health through load balancer (may need a delay)
    - echo "Waiting for application to be available at load balancer..."
    - sleep 60
    - echo "Checking application health at http://${LB_DNS}/_stcore/health"
    - curl -s -f -m 10 "http://${LB_DNS}/_stcore/health" || echo "Health check failed, application may need more time to become available"