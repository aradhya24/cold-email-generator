image: docker:20.10.16

services:
  - docker:20.10.16-dind

variables:
  DOCKER_HOST: tcp://docker:2375
  DOCKER_TLS_CERTDIR: ""
  DOCKER_DRIVER: overlay2
  DOCKER_REGISTRY: ${CI_REGISTRY}
  DOCKER_IMAGE: ${CI_REGISTRY}/aradhya24/cold-email-generator:${CI_COMMIT_SHA}
  AWS_USER: ubuntu
  LB_DNS: ${LB_DNS}

stages:
  - validate
  - build
  - deploy
  - monitor

validate:
  image: python:3.9-slim
  stage: validate
  script:
    - apt-get update && apt-get install -y python3-pip
    - pip install -r requirements.txt
    - python -c "import app.main" || echo "Validation failed but continuing"

build:
  stage: build
  script: 
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY 
    - docker build --pull -t $DOCKER_IMAGE .
    - docker tag $DOCKER_IMAGE $CI_REGISTRY/aradhya24/cold-email-generator:latest
    - docker push $DOCKER_IMAGE 
    - docker push $CI_REGISTRY/aradhya24/cold-email-generator:latest

deploy:
  stage: deploy
  image: python:3.9-slim
  script: |
    # Install required packages and setup in parallel
    apt-get update && apt-get install -y openssh-client awscli jq &
    mkdir -p ~/.ssh && chmod 700 ~/.ssh &
    echo "$AWS_SSH_KEY" | tr -d '\r' > ~/.ssh/id_rsa &
    wait
    
    chmod 600 ~/.ssh/id_rsa
    eval $(ssh-agent -s) && ssh-add ~/.ssh/id_rsa
    echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config

    # Setup AWS credentials
    export AWS_DEFAULT_REGION=us-east-1
    export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
    export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY

    # Get EC2 instance IP
    EC2_IP=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=cold-email-instance" "Name=instance-state-name,Values=running" --query "Reservations[0].Instances[0].PublicIpAddress" --output text)
    
    if [ -z "$EC2_IP" ]; then
      echo "No running instance found. Launching new instance..."
      chmod +x scripts/launch_ec2.sh
      ./scripts/launch_ec2.sh
      sleep 10
      EC2_IP=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=cold-email-instance" "Name=instance-state-name,Values=running" --query "Reservations[0].Instances[0].PublicIpAddress" --output text)
    fi

    # Define SSH command function with retries
    run_ssh_command() {
      local command="$1"
      for i in {1..3}; do
        if ssh -o ConnectTimeout=5 ${AWS_USER}@${EC2_IP} "$command"; then
          return 0
        fi
        sleep 10
      done
      return 1
    }

    # Test SSH connection
    run_ssh_command "echo SSH connection successful" || exit 1

    # Setup and deploy
    run_ssh_command "mkdir -p ~/k8s ~/scripts" || exit 1
    
    # Copy files in parallel
    scp scripts/setup-k8s.sh ${AWS_USER}@${EC2_IP}:~/scripts/ &
    scp scripts/deploy-k8s.sh ${AWS_USER}@${EC2_IP}:~/scripts/ &
    scp -r k8s/* ${AWS_USER}@${EC2_IP}:~/k8s/ &
    wait
    
    run_ssh_command "chmod +x ~/scripts/*.sh" || exit 1
    run_ssh_command "export GROQ_API_KEY=${GROQ_API_KEY} && ~/scripts/setup-k8s.sh" || exit 1
    
    # Copy docker-compose and nginx config
    scp docker-compose.yml nginx.conf ${AWS_USER}@${EC2_IP}:~/ && wait
    
    # Deploy application
    run_ssh_command "sudo docker login -u gitlab-ci-token -p ${CI_JOB_TOKEN} ${CI_REGISTRY}" || exit 1
    run_ssh_command "cd ~/ && export CI_REGISTRY=${CI_REGISTRY} && export CI_COMMIT_SHA=${CI_COMMIT_SHA} && export GROQ_API_KEY=${GROQ_API_KEY} && sudo -E docker-compose up -d" || exit 1
    
    echo "LB_DNS=${EC2_IP}" > lb_dns.env
    echo "Application deployed at http://${EC2_IP}"
  environment:
    name: production
    url: http://${LB_DNS}
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
  artifacts:
    reports:
      dotenv: lb_dns.env

monitor:
  stage: monitor
  image: python:3.9-slim
  script: |
    # Install required packages and setup in parallel
    apt-get update && apt-get install -y openssh-client awscli &
    mkdir -p ~/.ssh && chmod 700 ~/.ssh &
    echo "$AWS_SSH_KEY" | tr -d '\r' > ~/.ssh/id_rsa &
    wait
    
    chmod 600 ~/.ssh/id_rsa
    eval $(ssh-agent -s) && ssh-add ~/.ssh/id_rsa
    echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
    
    # Setup AWS credentials
    export AWS_DEFAULT_REGION=us-east-1
    export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
    export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
    
    # Get instance IP
    EC2_IP=$(aws ec2 describe-instances --filters "Name=tag:Name,Values=cold-email-instance" "Name=instance-state-name,Values=running" --query "Reservations[0].Instances[0].PublicIpAddress" --output text)
    
    # Define SSH command function with retries
    run_ssh_command() {
      local command="$1"
      for i in {1..3}; do
        if ssh -o ConnectTimeout=5 ${AWS_USER}@${EC2_IP} "$command"; then
          return 0
        fi
        sleep 10
      done
      return 1
    }
    
    # Run health checks in parallel
    run_ssh_command "kubectl get pods -n cold-email" &
    run_ssh_command "kubectl get svc -n cold-email" &
    wait
    
    # Check application health
    sleep 15
    curl -s -f -m 5 "http://${EC2_IP}/_stcore/health" || echo "Health check failed"
  rules:
    - if: $CI_COMMIT_BRANCH == "main"