image: docker:20.10.16

services:
  - docker:20.10.16-dind

variables:
  DOCKER_HOST: tcp://docker:2375
  DOCKER_TLS_CERTDIR: ""
  DOCKER_DRIVER: overlay2
  DOCKER_REGISTRY: ${CI_REGISTRY}
  DOCKER_IMAGE: ${CI_REGISTRY}/aradhya24/cold-email-generator:${CI_COMMIT_SHA}
  AWS_USER: ubuntu
  LB_DNS: ${LB_DNS}

stages:
  - validate
  - build
  - deploy
  - monitor

validate:
  image: python:3.9-slim
  stage: validate
  script:
    - apt-get update && apt-get install -y python3-pip
    - pip install -r requirements.txt
    - echo "Validating project structure..."
    - python -c "import app.main" || echo "Validation failed but continuing"

build:
  stage: build
  script: 
    - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY 
    - docker build --pull -t $DOCKER_IMAGE .
    - docker tag $DOCKER_IMAGE $CI_REGISTRY/aradhya24/cold-email-generator:latest
    - docker push $DOCKER_IMAGE 
    - docker push $CI_REGISTRY/aradhya24/cold-email-generator:latest

deploy_setup:
  stage: deploy
  image: python:3.9-slim
  only:
    - main
  when: manual
  script:
    - apt-get update && apt-get install -y openssh-client gettext-base awscli
    - mkdir -p ~/.ssh && chmod 700 ~/.ssh
    - echo "$AWS_SSH_KEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval $(ssh-agent -s) && ssh-add ~/.ssh/id_rsa
    - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
    
    # Get healthy EC2 instance
    - chmod +x scripts/get_healthy_instance.sh
    - EC2_IP=$(./scripts/get_healthy_instance.sh)
    - echo "Using EC2 instance with IP $EC2_IP for deployment"
    
    # Setup Kubernetes
    - ssh ${AWS_USER}@${EC2_IP} "mkdir -p ~/k8s ~/scripts"
    - scp -r k8s/* ${AWS_USER}@${EC2_IP}:~/k8s/
    - scp scripts/setup-k8s.sh ${AWS_USER}@${EC2_IP}:~/scripts/
    - ssh ${AWS_USER}@${EC2_IP} "chmod +x ~/scripts/setup-k8s.sh"
    - ssh ${AWS_USER}@${EC2_IP} "export GROQ_API_KEY=${GROQ_API_KEY} && ~/scripts/setup-k8s.sh"

deploy:
  stage: deploy
  image: python:3.9-slim
  before_script:
    - apt-get update
    - apt-get install -y curl unzip openssh-client gettext-base
    # Install AWS CLI v2
    - curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
    - unzip awscliv2.zip
    - ./aws/install
    # Setup SSH
    - mkdir -p ~/.ssh && chmod 700 ~/.ssh
    - echo "$AWS_SSH_KEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval $(ssh-agent -s) && ssh-add ~/.ssh/id_rsa
    - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
    - chmod 600 ~/.ssh/config
  script: |
    # Configure AWS credentials
    export AWS_DEFAULT_REGION=us-east-1
    export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
    export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
    
    # Use a static EC2 IP for now until we can debug the script
    if [ -n "$AWS_EC2_IP" ]; then
      EC2_IP=$AWS_EC2_IP
      echo "Using provided EC2 IP: $EC2_IP"
    else
      # Try to find an instance directly
      echo "Finding EC2 instance with tag Name=cold-email-instance"
      EC2_IP=$(aws ec2 describe-instances \
        --filters "Name=tag:Name,Values=cold-email-instance" "Name=instance-state-name,Values=running" \
        --query "Reservations[0].Instances[0].PublicIpAddress" \
        --output text)
      
      if [ "$EC2_IP" == "None" ] || [ -z "$EC2_IP" ]; then
        echo "No instance found with tag. Using default EC2 IP from environment"
        # Default to the provided IP if no instance is found
        EC2_IP=${AWS_EC2_IP}
      fi
    fi
    
    echo "Deploying to instance: $EC2_IP"
    
    # Check SSH connectivity
    echo "Testing SSH connection..."
    ssh -o ConnectTimeout=10 ${AWS_USER}@${EC2_IP} "echo SSH connection successful"
    
    # Create directories on the instance
    ssh ${AWS_USER}@${EC2_IP} "mkdir -p ~/k8s ~/scripts"
    
    # Copy Kubernetes config files
    scp -r k8s/* ${AWS_USER}@${EC2_IP}:~/k8s/
    
    # Copy and execute setup script
    scp scripts/setup-k8s.sh ${AWS_USER}@${EC2_IP}:~/scripts/
    ssh ${AWS_USER}@${EC2_IP} "chmod +x ~/scripts/setup-k8s.sh"
    ssh ${AWS_USER}@${EC2_IP} "export GROQ_API_KEY=${GROQ_API_KEY} && ~/scripts/setup-k8s.sh"
    
    # Process the deployment file with environment variables
    envsubst < k8s/deployment.yaml > k8s/deployment.tmp.yaml
    
    # Copy deployment files and execute deployment
    scp k8s/deployment.tmp.yaml ${AWS_USER}@${EC2_IP}:~/k8s/deployment.yaml
    scp scripts/deploy.sh ${AWS_USER}@${EC2_IP}:~/scripts/
    ssh ${AWS_USER}@${EC2_IP} "chmod +x ~/scripts/deploy.sh && ~/scripts/deploy.sh"
  environment:
    name: production
    url: http://${LB_DNS}
  rules:
    - if: $CI_COMMIT_BRANCH == "main"
      when: manual
    - when: never

monitor:
  stage: monitor
  image: python:3.9-slim
  only:
    - main
  script:
    - apt-get update && apt-get install -y openssh-client curl awscli
    - mkdir -p ~/.ssh && chmod 700 ~/.ssh
    - echo "$AWS_SSH_KEY" | tr -d '\r' > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - eval $(ssh-agent -s) && ssh-add ~/.ssh/id_rsa
    - echo -e "Host *\n\tStrictHostKeyChecking no\n\n" > ~/.ssh/config
    
    # Get healthy EC2 instance
    - chmod +x scripts/get_healthy_instance.sh
    - EC2_IP=$(./scripts/get_healthy_instance.sh)
    
    # Check Kubernetes deployment
    - ssh ${AWS_USER}@${EC2_IP} "kubectl get pods -n cold-email"
    - ssh ${AWS_USER}@${EC2_IP} "kubectl get svc -n cold-email"
    
    # Get load balancer DNS if not set
    - |
      if [ -z "$LB_DNS" ]; then
        export LB_DNS=$(aws elbv2 describe-load-balancers \
          --names cold-email-lb \
          --query 'LoadBalancers[0].DNSName' \
          --output text)
      fi
    
    # Check application health through load balancer (may need a delay)
    - echo "Waiting for application to be available at load balancer..."
    - sleep 60
    - echo "Checking application health at http://${LB_DNS}/_stcore/health"
    - curl -s -f -m 10 "http://${LB_DNS}/_stcore/health" || echo "Health check failed, application may need more time to become available"